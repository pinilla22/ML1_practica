---
title: "Insurance Analysis"
author: 
- Juan Manuel Jiménez
- Javier Pinilla
- Luis Rus
date: "12/16/2019"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: flatly
    code_folding: hide
  # pdf_document: default
---

# Objetivo del Proyecto

El objetivo del proyecto es poder identificar que factores de los asegurados afectan en la siniestralidad de las aseguradoras de autos. 

La siniestralidad afecta de lleno en la cuenta de resultados de la aseguradora y una buena comprensión de estos factores hará que la compañía pueda cuantificar bien el riesgo y por lo tanto el importe a cobrar al asegurado e incluso que pueda rechazar ciertos riesgos que no quiera asumir.

Para poder realizar este objetivo contamos con con un dataset que contiene informacion sobre el tomador y el vehículo a asegurar. Además vamos a tener dos variables objetivo:

+ Por un lado la variable que nos indica si ha tenido o no accidente en el año en curso.
+ Por otro la variable de cuantía del siniestro en el año en curso.

Para ello el dataset tiene 27 variables que vamos a explicar a continuación:

**ID** - ID de poliza

**KIDSDRIV** - Numero de adolescentes con licencia de conducir en la unidad familiar.

**BIRTH** -	Año de nacimiento.

**AGE** -	Edad.

**HOMEKIDS** - Adolescentes viviendo en la casa de la unidad familiar.

**YOJ** - Años en el trabajo.

**INCOME** - Ingresos anuales.

**PARENT1** - Flag de Familia uniparental.

**HOME_VAL**- Valor de la vivienda.

**MSTATUS**- Estado Civil (Soltero-Casado).

**GENDER**- Sexo.

**EDUCATION**- Nivel de educación.

**OCCUPATION**-	Ocupacion.

**TRAVTIME**- Tiempo diario en minutos al centro de trabajo.

**CAR_USE**- Uso del vehiculo.

**BLUEBOOK**- Valor actual del vehiculo.

**TIF**- Tiempo en vigor en la compañía actual.

**CAR_TYPE**- Tipo de vehiculo.

**RED_CAR**- Flag Vehiculo de color Rojo.

**OLDCLAIM**- Valor de los siniestros anteriores al año en curso.

**CLM_FREQ**- Frecuencia de los siniestros anteriores al año en curso.

**REVOKED**- Siniestro revocado por la compañia.

**MVR_PTS**- Nº de puntos retirados del carnet.

**CLM_AMT**- Cuantia del siniestro en el año en curso.

**CAR_AGE**- Años del vehiculo.

**CLAIM_FLAG**- Flag de siniestro año en curso.

**URBANICITY**- Lugar de conduccion - Urbano vs. Rural

Para poder realizar el proyecto vamos a necesitar las siguientes librerías. Algunas de estas librerías son específicas para el tratamiento de nulos, para la representación gráfica o para el desarrollo de modelos.


```{r message=FALSE}
library(dplyr)
library(tidyr)
library(ggplot2)
library(egg)
library(GGally)

library(ISLR)
library(car)
library(DMwR2)
library(faraway)
library(mlbench)

library(knitr)
library(kableExtra)
library(htmltools)
library(bsplus)
library(RColorBrewer)

library(lattice)
library(VIM)
library(mice)

library(stringr)
library(corrplot)

library(tidyverse)
library(lsr)
library(cowplot)

library(tidymodels)
library(skimr)
library(tibble)

library(lubridate)
library(padr)
library(caret)

library(partykit)
library(DMwR)
library(lime)
library(parsnip)

library(randomForest)
library(cluster)
library(RColorBrewer)
library(factoextra)

library(readr)
library(dplyr)
library(ggplot2)
library(stringr)
library(Rtsne)
library(pROC)
library(ggpubr)
library(ROCR)

library(rpart)
library(rpart.plot)

```

# Estudio exploratorio de los datos

Importamos el dataset obtenido en kaggle desde un CSV con separación por comas.

```{r}
insurance <- read.csv(file="car_insurance_claim.csv", header=TRUE, sep=",")
```

Primero vamos a mirar la dimensión del dataset para realizar una división eficaz en dos subsets. Uno será el de entrenamiento y el otro el de test.

```{r, echo=FALSE}
dim(insurance)
```

Al ver que la longitud de la muestra es de 10302 vamos a repartir un 68% en train al cual denominaremos "train", 20 en test que denominaremos "test" y un 12 para validation.

```{r}
set.seed(101)
sample <- sample.int(n = nrow(insurance), size = floor(.80*nrow(insurance)), replace = F)
train_temp <- insurance[sample, ]
test  <- insurance[-sample, ]
# Validation
sample_validation <- sample.int(n = nrow(train_temp), size = floor(.85*nrow(train_temp)), replace = F)
train <- train_temp[sample_validation,]
validation <- train_temp[-sample_validation,]

# Contamos el numero de líneas para el análisis.
n_train <- nrow(train)
n_test <- nrow(test)
n_validation <- nrow(validation)
```

Una vez generados los dos subsets vamos a realizar un primer análisis visual del dataset viendo los cinco primeros registros.

# Limpieza de los datos

## Transformaciones de variables cuantitativas

El primer paso es adaptar el formato de las variables que se encuentran en dólares, ya que se presentan con el símbolo de dolar delante y con separados de miles con coma. 

```{r }
# Cambiar "," por "." y eliminar los $

train$INCOME <- str_replace_all(train$INCOME, ",", "")
train$INCOME <- str_sub(train$INCOME, 2, -1)

train$HOME_VAL <- str_replace_all(train$HOME_VAL, ",", "")
train$HOME_VAL <- str_sub(train$HOME_VAL, 2, -1)

train$BLUEBOOK <- str_replace_all(train$BLUEBOOK, ",", "")
train$BLUEBOOK <- str_sub(train$BLUEBOOK, 2, -1)

train$OLDCLAIM <- str_replace_all(train$OLDCLAIM, ",", "")
train$OLDCLAIM <- str_sub(train$OLDCLAIM, 2, -1)

train$CLM_AMT <- str_replace_all(train$CLM_AMT, ",", "")
train$CLM_AMT <- str_sub(train$CLM_AMT, 2, -1)
```

```{r}
sapply(train, class)
```

Tras esta transformación, vemos que las variables han pasado a ser de tipo "character" por lo que vamos a convertirlas en numéricas.

```{r}
# Cambiar variables tipo "character" a "numeric"

train$INCOME <- as.numeric(train$INCOME)

train$HOME_VAL <- as.numeric(train$HOME_VAL)

train$BLUEBOOK <- as.numeric(train$BLUEBOOK)

train$OLDCLAIM <- as.numeric(train$OLDCLAIM)

train$CLM_AMT <- as.numeric(train$CLM_AMT)

sapply(train, class)
```
Aqui podemos ver que ya están en formato numérico por lo que la transformación ha funcionado.

## Procesado de variables cualitativas

Mediante el resumen obtenido con la funcion summary se puede ver que nuestro dataset contiene variables categóricas, ya sea tipo booleano o con varios niveles. Vamos a identificarlas y en algunos casos a transformarlas.

En primer lugar, es necesario quitar el prefijo "z_" de algunos valores que encontramos en las variables MSTATUS, GENDER, CAR_TYPE y URBANICITY.

```{r warning=FALSE}
# Quitar prefijo z_
train <- train %>% mutate_if(is.factor,funs(str_replace(.,"z_", "")))
sapply(train, class)
```

Por otro lado, vamos a obtener un listado del numero de posibles valores que pueden tomar todos los campos del dataset. Para ello utilizamos la funcion "gather"" para poner los nombres de las columnas como filas y agrupamos y contamos el número de valores distintos por columna.

```{r}
num_valores_variable <- train %>% gather() %>% group_by(key) %>%
summarize(uniques = n_distinct(value))

num_valores_variable <- data.frame(num_valores_variable,stringsAsFactors=FALSE)

num_valores_variable <- data.frame(Variable = num_valores_variable[,1],Num.uniques = num_valores_variable[,2],stringsAsFactors=FALSE)

num_valores_variable$Variable <- as.vector(num_valores_variable$Variable)

num_valores_variable[order(num_valores_variable[,2]),]
```

Viendo la tabla de arriba podemos decir que tenemos 8 variables que tienen dos posibles niveles y otras 3 (OCCUPATION, CAR_TYPE Y EDUCATION) que son categóricas con más de dos niveles.

Vamos a explorar estas variables a ver que posibles valores pueden tomar.

```{r, echo=FALSE}
# EDUCATION
print("EDUCATION")
unique(train$EDUCATION)
# OCUPATION
print("OCCUPATION")
unique(train$OCCUPATION)
# CAR_TYPE
print("CAR_TYPE")
unique(train$CAR_TYPE)
```

Vemos que la variable EDUCATION tiene 5 niveles, la de "CAR_TYPE" tiene 7 y la de "OCCUPATION" tiene 10, una de ellas en blanco por lo que vamos a generar una categoría "others" con estos registros en los que no tenemos información. 

Ademas Colocamos la variable "EDUCATION" por categorias temporales para hacer un mejor análisis posterior de esta variable.

```{r}
train$OCCUPATION <- factor(train$OCCUPATION,
                          ordered = FALSE,
                          levels = c("", "Clerical", "Doctor", "Home Maker", "Lawyer", "Manager", "Professional", "Student", "Blue Collar"),
                          labels = c("Others", "Clerical", "Doctor", "Home Maker", "Lawyer", "Manager", "Professional", "Student", "Blue Collar"))
```

Las transformaciones anteriores convierten las variables tratadas a tipo "character", por lo que vamos a convertir a factores las variables que originalmente eran categóricas.

```{r}
# Pasar columnas tipo "character" a "factor"

train <- train %>% mutate_if(is.character, as.factor)
sapply(train, class)
```

Al ver que las variables categóricas con dos posibles valores no tienen nulos vamos a convertirlas en valores en 0 y 1 donde el 1 será el valor "Si", "Comercial" , "Urbano" y "Mujer" dependiendo la variable.

```{r}
# Creamos una tabla con las variables y los valores que transformaremos con el valor 1

variables_binarias <- data.frame(Variable = c("CAR_USE","MSTATUS","PARENT1","RED_CAR","REVOKED","GENDER","URBANICITY"),
	valor_1 = c("Commercial","Yes","Yes","yes","Yes","M","Highly Urban/ Urban"),
	stringsAsFactors=FALSE)

for(i in 1:length(variables_binarias$Variable)){
  var <- variables_binarias$Variable[i]
  true_value <- variables_binarias$valor_1[i]
  train[,var] <- ifelse(train[,var] == true_value,1,0)
}
```

```{r, echo=FALSE}
train_numeric <- train %>% na.omit() %>% select(CAR_AGE, CLAIM_FLAG, MVR_PTS, CLM_FREQ, TIF, TRAVTIME, AGE, HOMEKIDS, YOJ, KIDSDRIV, INCOME, HOME_VAL, BLUEBOOK, CLM_AMT, OLDCLAIM) 

cor(train_numeric, method = "spearman") %>% 
corrplot( method = 'color', addCoef.col = "black", tl.cex=0.7, number.cex=0.6)
```

Efectivamente así lo parece por lo que vamos a hacer un análisis de como se distribuyen los nulos entre estas variables

### Imputación variable INCOME

```{r, echo=FALSE}
train %>% select(INCOME, HOME_VAL) %>% marginplot()
```

En el gráfico de arriba podemos observar que las variables HOME_VAL e INCOME tienen una correlación positiva y que los registros en los que la otra variable son nulos y no nulos se distribuyen de la misma manera, por lo que podríamos utilizar un método de regresión lineal para rellenar estos valores aunque como hemos comentado antes se puede ver la linea de puntos en el cero procedente de HOME_VAL. Teniendo en cuenta esto, no pensamos que pueda ser la variable más acertada para rellenar nulos. Además, debido a esto, al hacerlo algunos valores de INCOME aparecen en negativo.

Sabiendo lo anterior, vamos a intentar utilizar otra variable que tenga correlación con INCOME y que sus datos sean robustos.

En este caso proponemos utilizar BLUEBOOK que es el valor del coche y que tiene cierta correlación con INCOME. Además creemos que puede ser mas acertado utilizar el método KNN.

```{r, echo=FALSE}
train %>% select(INCOME, BLUEBOOK) %>% VIM::kNN() %>% marginplot(., delimiter="_imp")
```

Lo que vemos en el gráfico es que la imputación de los valores faltantes por el metodo KNN en su mayoría sería de manera lineal con lo que nos convence como para utilizarlo de proxy. Podemos decir que podríamos buscar otros métodos como transformarlas con logaritmos para buscar relaciones más ajustadas y despues deshacer dicho cambio.

```{r, echo=FALSE}
stoch_imp <- train %>% VIM::kNN(., variable=c("INCOME","BLUEBOOK"))
d1 = train$INCOME
train$INCOME <- stoch_imp$INCOME
```

```{r warning=FALSE, message=FALSE}
x <- data.frame(d1 = d1, d2 = stoch_imp$INCOME)
data <- melt(x)
ggplot(data,aes(x=value, fill=variable)) + geom_density(alpha=0.25)
```

### Imputación variable CAR_AGE

Una vez imputado INCOME vamos a analizar ahora CAR_AGE para ver como se comporta contra otras variables. En concreto tomamos las variables con las que tiene mas correlacion y lo graficamos.

```{r echo=FALSE, fig.height=8, fig.width=10}
train %>% select(4,25,7,12) %>%
  na.omit() %>%
  ggpairs(columns = 1:3, ggplot2::aes(colour=EDUCATION))
```

Vemos que con Income tiene una correlaciónde un 40%. Vamos a ver estas dos variables más en detalle.

```{r, echo=FALSE}
train %>% select(INCOME, CAR_AGE) %>% marginplot()
```

En ambos gráficos podemos observar como la distribucion de CAR_AGE varia por la variable "EDUCATION" y además está correlacionada de manera significativa con INCOME por lo que vamos a realizar un KNN con estas variables.


```{r, echo=FALSE}
stoch_imp <- train %>% VIM::kNN(., variable=c("CAR_AGE", "INCOME","EDUCATION"))
d1 = train$CAR_AGE
train$CAR_AGE <- stoch_imp$CAR_AGE
```

```{r warning=FALSE, message=FALSE}
x <- data.frame(d1 = d1, d2 = stoch_imp$CAR_AGE)
data <- melt(x)
ggplot(data,aes(x=value, fill=variable)) + geom_density(alpha=0.25)
```

Adicionalmente como habiamos visto, hay un registro cuyo valor de CAR_AGE es -3 asi que vamos a eliminar este registro. Podríamos aplicar otras reglas como imputarle un 1 o un 3 entendiendo que ha sido un error de imputación pero al ser solo un registros no afectamos el análisis eliminandolo.

```{r}
train <- train[train$CAR_AGE > -1, ]
summary(train$CAR_AGE)
```

### Imputación variable YOJ

Ahora vamos a rellenar los valores faltantes respecto a los años en el trabajo(YOJ) y a la edad(AGE) teniendo en cuenta que para esta última variable el porcentaje de nulos no supera el 0.07%.

Primero vamos a analizar el comportamiento de estas variables contra las variables que mas correlación tienen.

```{r eval=FALSE, fig.height=8, fig.width=10}
train %>% select(4,6,7,12) %>%
  na.omit() %>%
  ggpairs(columns = 1:3, ggplot2::aes(colour=EDUCATION))
```

Aplicamos una imputación de datos simular a la de CAR_AGE. Según la tabla de correlación de arriba y dada su relación con la variable EDUCATION, de forma indirecta, haremos imputación por KNN teniendo en cuenta los valores de las variables INCOME y EDUCATION y añadiré también las variables HOMEKIDS y AGE, en este caso.

Podemos ver que a medida que avanzan los años de trabajo aumenta el rango de la distribución del income por año y de ahi entendemos que tambien la media de cada año por lo que nos parece que KNN es un método muy apropiado para la imputación.

```{r, echo=FALSE}
stoch_imp <- train %>% VIM::kNN(., variable=c("INCOME","YOJ","EDUCATION", "HOMEKIDS", "AGE"))
d1 = train$YOJ
train$YOJ <- stoch_imp$YOJ
```

```{r warning=FALSE, message=FALSE}
x <- data.frame(d1 = d1, d2 = stoch_imp$YOJ)
data <- melt(x)
ggplot(data,aes(x=value, fill=variable)) + geom_density(alpha=0.25)
```

### Imputación variable AGE

Ahora rellenamos los 7 registros de AGE con una formula ya que tenemos la fecha de nacimiento y lo que vamos a hacer es calcularlo para estos seis registros que nos faltan.

```{r}
train$BIRTH <- as.character(train$BIRTH)
train <- train %>% mutate(AGE=ifelse(is.na(AGE), 120-as.numeric(substr(BIRTH, nchar(BIRTH)-1, nchar(BIRTH))), AGE))
```

### Imputación variable HOME_VAL

Finalmente rellenamos HOME_VAL aunque la mantendremos en cuarentena como un KNN de la variable INCOME

```{r warning=FALSE}
stoch_imp <- train %>%  VIM::kNN(., variable=c("INCOME","HOME_VAL"), k=1)
train$INCOME <- stoch_imp$INCOME
train$HOME_VAL <- stoch_imp$HOME_VAL
```

### Resumen imputación datos faltantes

```{r echo=FALSE}
missing_values <- aggr(train, col=c('navyblue','red'), numbers=TRUE, sortVars=TRUE,
                  labels=names(train), cex.axis=.7, gap=3, 
                  ylab=c("Histogram of missing data","Pattern"))
```

```{r}
summary(train)
```

```{r echo=FALSE}
train$bin_OLDCLAIM <- ifelse(train$OLDCLAIM > 0,1,0)
train$bin_HOMEKIDS <- ifelse(train$HOMEKIDS > 3,1,0)
train["bin_KIDSDRIV"] <- ifelse(train["KIDSDRIV"] > 0,1,0)
train["bin_TIF"] <- ifelse(train["TIF"] < 3 | train["TIF"] > 15 ,0,1)
train["bin_AGE"] <- ifelse(train["AGE"] < 26 | train["AGE"] > 57 ,1,0)
train["bin_MVR_PTS"] <- ifelse(train["MVR_PTS"] > 6,1,0)
train["bin_OCCUPATION"] <- ifelse(train["OCCUPATION"] == "Lawyer" | train["OCCUPATION"] == "Manager"| train["OCCUPATION"] == "Doctor" ,0,1)
train["bin_EDUCATION"] <- ifelse(train["EDUCATION"] == "1-<High School" | train["EDUCATION"] == "2-High School",1,0)
train["bin_CAR_TYPE"] <- ifelse(train["CAR_TYPE"] == "Minivan",0,1)

# Variables logarítmicas
train$CLM_AMT_log <- log(train$CLM_AMT,10)
train$INCOME_log <- log(train$INCOME+1,10)
train$BLUEBOOK_log <- log(train$BLUEBOOK,10)
train$OLDCLAIM_log <- log(train$OLDCLAIM+1,10)
```


```{r echo=FALSE}
#train$CLAIM_FLAG <- factor(train$CLAIM_FLAG)

train$EDUCATION <- factor(train$EDUCATION,
                          ordered = TRUE,
                          levels = c("<High School", "High School", "Bachelors", "Masters", "PhD"),
                          labels = c("1-<High School", "2-High School", "3-Bachelors", "4-Masters", "PhD"))


```
## Consideraciones sobre el modelo a desarrollar

Una vez realizado todo el análisis procederiamos a seleccionar variables para nuestro modelo. Aunque sería interesante contar con dos modelos en secuencia que nos permitieran predecir:

  1. Si va a tener accidente o no
  2. En el caso de tener accidente, cúanto sería el coste

No podemos predecir el primer caso mediante un modelo lineal, necesitamos alguno de los modelos de clasificación que serán estudiados en un futuro. A priori, creemos que el modelo que más se ajustaría sería un GLM, que es el que se utiliza en las compañías de seguros para este tipo de problemas.

Para este proyecto vamos a simular que contamos con el primer modelo. Para ello, vamos utilizar sólo aquellos registros donde el CLAIM_FLAG sea 1, esto hace que nos quedemos sólo con aquellos registros que han tenido accidente.

Con esto el siguiente paso sería analizar las variables pero esta vez contra nuestra segunda variable objetivo que es el importe del siniestro (CLM_AMT)



# MODIFICACIONES PARA EL SUBSET DE TEST

```{r}

# Cambiar "," por "." y eliminar los $
test$INCOME <- str_replace_all(test$INCOME, ",", "")
test$INCOME <- str_sub(test$INCOME, 2, -1)

test$HOME_VAL <- str_replace_all(test$HOME_VAL, ",", "")
test$HOME_VAL <- str_sub(test$HOME_VAL, 2, -1)

test$BLUEBOOK <- str_replace_all(test$BLUEBOOK, ",", "")
test$BLUEBOOK <- str_sub(test$BLUEBOOK, 2, -1)

test$OLDCLAIM <- str_replace_all(test$OLDCLAIM, ",", "")
test$OLDCLAIM <- str_sub(test$OLDCLAIM, 2, -1)

test$CLM_AMT <- str_replace_all(test$CLM_AMT, ",", "")
test$CLM_AMT <- str_sub(test$CLM_AMT, 2, -1)

# Cambiar variables tipo "character" a "numeric"
test$INCOME <- as.numeric(test$INCOME)

test$HOME_VAL <- as.numeric(test$HOME_VAL)

test$BLUEBOOK <- as.numeric(test$BLUEBOOK)

test$OLDCLAIM <- as.numeric(test$OLDCLAIM)

test$CLM_AMT <- as.numeric(test$CLM_AMT)

# Quitar prefijo z_
test <- test %>% mutate_if(is.factor,funs(str_replace(.,"z_", "")))

# Renombrado labels variable OCCUPATION
test$OCCUPATION <- factor(test$OCCUPATION,
                          ordered = FALSE,
                          levels = c("", "Clerical", "Doctor", "Home Maker", "Lawyer", "Manager", "Professional", "Student", "Blue Collar"),
                          labels = c("Others", "Clerical", "Doctor", "Home Maker", "Lawyer", "Manager", "Professional", "Student", "Blue Collar"))

test$EDUCATION <- factor(test$EDUCATION,
                          ordered = TRUE,
                          levels = c("<High School", "High School", "Bachelors", "Masters", "PhD"),
                          labels = c("1-<High School", "2-High School", "3-Bachelors", "4-Masters", "PhD"))


# Pasar columnas tipo "character" a "factor"
test <- test %>% mutate_if(is.character, as.factor)

# Creamos una tabla con las variables y los valores que transformaremos con el valor 1
for(i in 1:length(variables_binarias$Variable)){
  var <- variables_binarias$Variable[i]
  true_value <- variables_binarias$valor_1[i]
  test[,var] <- ifelse(test[,var] == true_value,1,0)
}

# Imputación de datos faltantes

train_knn_imp <- train %>% select(INCOME, BLUEBOOK, CAR_AGE, EDUCATION, YOJ, HOMEKIDS, AGE)
test_knn_imp <- test %>% select(INCOME, BLUEBOOK, CAR_AGE, EDUCATION, YOJ, HOMEKIDS, AGE)

train_knn_imp$isTrain <- rep(1, nrow(train_knn_imp))
test_knn_imp$isTrain <- rep(0, nrow(test_knn_imp))
train_test_knn_imp <- rbind(train_knn_imp,test_knn_imp)
sapply(test, function(x) sum(is.na(x)))

# Imputado de missings varible INCOME
knn_income_imp <- train_test_knn_imp %>% VIM::kNN(., variable=c("INCOME","BLUEBOOK")) %>% filter(isTrain==0)
test$INCOME <- knn_income_imp$INCOME

# Imputado de missings varible CAR_AGE
knn_carage_imp <- train_test_knn_imp %>% VIM::kNN(., variable=c("CAR_AGE", "INCOME","EDUCATION")) %>%   filter(isTrain==0)
test$CAR_AGE <- knn_carage_imp$CAR_AGE

# Imputado de missings varible YOJ
knn_yoj_imp <- train_test_knn_imp %>% VIM::kNN(., variable=c("INCOME","YOJ","EDUCATION", "HOMEKIDS", "AGE")) %>% filter(isTrain==0)
test$YOJ <- knn_yoj_imp$YOJ

# Imputado de missings variable AGE
test$BIRTH <- as.character(test$BIRTH)
test <- test %>% mutate(AGE=ifelse(is.na(AGE), 120-as.numeric(substr(BIRTH, nchar(BIRTH)-1, nchar(BIRTH))), AGE))
sapply(test, function(x) sum(is.na(x)))

test["education_bin"] <- ifelse(test["EDUCATION"] == "1-<High School" | test["EDUCATION"] == "2-High School",1,0)
test_target <- test
test_target$CLM_AMT_log <- log(test$CLM_AMT,10)
test_target$BLUEBOOK_log <- log(test$BLUEBOOK,10)
test_target$OLDCLAIM_log <- log(test$OLDCLAIM+1,10)
#test_target$CLAIM_FLAG <- factor(test_target$CLAIM_FLAG)
```
```{r results = "hide"}
# MODIFICACIONES PARA EL SUBSET DE VALIDATION

# Cambiar "," por "." y eliminar los $
validation$INCOME <- str_replace_all(validation$INCOME, ",", "")
validation$INCOME <- str_sub(validation$INCOME, 2, -1)

validation$HOME_VAL <- str_replace_all(validation$HOME_VAL, ",", "")
validation$HOME_VAL <- str_sub(validation$HOME_VAL, 2, -1)

validation$BLUEBOOK <- str_replace_all(validation$BLUEBOOK, ",", "")
validation$BLUEBOOK <- str_sub(validation$BLUEBOOK, 2, -1)

validation$OLDCLAIM <- str_replace_all(validation$OLDCLAIM, ",", "")
validation$OLDCLAIM <- str_sub(validation$OLDCLAIM, 2, -1)

validation$CLM_AMT <- str_replace_all(validation$CLM_AMT, ",", "")
validation$CLM_AMT <- str_sub(validation$CLM_AMT, 2, -1)

# Cambiar variables tipo "character" a "numeric"
validation$INCOME <- as.numeric(validation$INCOME)

validation$HOME_VAL <- as.numeric(validation$HOME_VAL)

validation$BLUEBOOK <- as.numeric(validation$BLUEBOOK)

validation$OLDCLAIM <- as.numeric(validation$OLDCLAIM)

validation$CLM_AMT <- as.numeric(validation$CLM_AMT)

# Quitar prefijo z_
validation <- validation %>% mutate_if(is.factor,funs(str_replace(.,"z_", "")))

# Renombrado labels variable OCCUPATION
validation$OCCUPATION <- factor(validation$OCCUPATION,
                          ordered = FALSE,
                          levels = c("", "Clerical", "Doctor", "Home Maker", "Lawyer", "Manager", "Professional", "Student", "Blue Collar"),
                          labels = c("Others", "Clerical", "Doctor", "Home Maker", "Lawyer", "Manager", "Professional", "Student", "Blue Collar"))

# Pasar columnas tipo "character" a "factor"
validation <- validation %>% mutate_if(is.character, as.factor)

# Creamos una tabla con las variables y los valores que transformaremos con el valor 1
for(i in 1:length(variables_binarias$Variable)){
  var <- variables_binarias$Variable[i]
  true_value <- variables_binarias$valor_1[i]
  validation[,var] <- ifelse(validation[,var] == true_value,1,0)
}

# Imputación de datos faltantes

train_knn_imp <- train %>% select(INCOME, BLUEBOOK, CAR_AGE, EDUCATION, YOJ, HOMEKIDS, AGE)
validation_knn_imp <- validation %>% select(INCOME, BLUEBOOK, CAR_AGE, EDUCATION, YOJ, HOMEKIDS, AGE)

train_knn_imp$isTrain <- rep(1, nrow(train_knn_imp))
validation_knn_imp$isTrain <- rep(0, nrow(validation_knn_imp))
train_validation_knn_imp <- rbind(train_knn_imp,validation_knn_imp)
sapply(validation, function(x) sum(is.na(x)))

# Imputado de missings varible INCOME
knn_income_imp <- train_validation_knn_imp %>% VIM::kNN(., variable=c("INCOME","BLUEBOOK")) %>% filter(isTrain==0)
validation$INCOME <- knn_income_imp$INCOME

# Imputado de missings varible CAR_AGE
knn_carage_imp <- train_validation_knn_imp %>% VIM::kNN(., variable=c("CAR_AGE", "INCOME","EDUCATION")) %>%   filter(isTrain==0)
validation$CAR_AGE <- knn_carage_imp$CAR_AGE

# Imputado de missings varible YOJ
knn_yoj_imp <- train_validation_knn_imp %>% VIM::kNN(., variable=c("INCOME","YOJ","EDUCATION", "HOMEKIDS", "AGE")) %>% filter(isTrain==0)
validation$YOJ <- knn_yoj_imp$YOJ

# Imputado de missings variable AGE
validation$BIRTH <- as.character(validation$BIRTH)
validation <- test %>% mutate(AGE=ifelse(is.na(AGE), 120-as.numeric(substr(BIRTH, nchar(BIRTH)-1, nchar(BIRTH))), AGE))
sapply(validation, function(x) sum(is.na(x)))

validation["education_bin"] <- ifelse(validation["EDUCATION"] == "1-<High School" | validation["EDUCATION"] == "2-High School",1,0)
validation_target <- validation
validation_target$CLM_AMT_log <- log(validation$CLM_AMT,10)
validation_target$BLUEBOOK_log <- log(validation$BLUEBOOK,10)
validation_target$OLDCLAIM_log <- log(validation$OLDCLAIM+1,10)
```


Obtenemos un error medio de 2904,47€ para las predicciones obtenidas del subset de validation.

# Conclusiones

Tras el análisis del modelo obtenido, podemos concluir que el modelo de regresión lineal construido no es capaz de explicar la variable objetivo CLM_AMT. Creemos que con los datos disponibles no recogemos toda la información que deberíamos para poder predecir esta variable, ya que en muchos de estos accidentes la cuantía no solo depende de los datos del propio asegurado sino que suelen haber más personas/activos involucrados de los que no tenemos ninguna información. En mucha ocasiones las aseguradoras piden como dato el código postal de la persona para poder ver cual es el valor medio de los vehículos de la zona con los cuales sería más probable que esta persona tuviera un accidente.

## Trabajo futuro

Tenemos la impresión de que con estos datos si que seríamos capaces de poder explicar la variable objetivo CLAIM_FLAG, que nos predeciría si la persona va a tener un accidente o no. Con esta información seríamos capaces de gestionar el riesgo de la cartera, que afecta directamente al beneficio.

## Modelos para la predicción de la variable CLAIM FLAG

Como comentabamos en el apartado anterior vamos a aplicar los modelos de clasificación tanto supervisados como no supervisados.

Primero vamos a preparar la BBDD para realizar los cálculos seleccionando las variables y dando labels a la variable objetivo de NOacc y SIacc dependiendo de si es 0 o 1.

```{r echo=FALSE}
train_random_forest <- train %>% select("OLDCLAIM", "HOMEKIDS", "KIDSDRIV","TIF","AGE","MVR_PTS",
"OCCUPATION","EDUCATION","CAR_TYPE","CLAIM_FLAG", "YOJ","PARENT1","GENDER", "TRAVTIME","CAR_USE","CAR_TYPE","RED_CAR","CLM_FREQ", "URBANICITY", "BLUEBOOK",)

train_kmeans <- train_random_forest %>% mutate_if(is.factor,as.numeric) %>% mutate_if(is.integer,as.numeric)

train_random_forest$CLAIM_FLAG <- factor(train_random_forest$CLAIM_FLAG, levels = c("0", "1"), labels = c("NOacc", "SIacc"))
```

```{r echo=FALSE}
test_random_forest <- test_target %>% select("OLDCLAIM", "HOMEKIDS", "KIDSDRIV","TIF","AGE","MVR_PTS",
"OCCUPATION","EDUCATION","CAR_TYPE","CLAIM_FLAG", "YOJ","PARENT1","GENDER", "TRAVTIME","CAR_USE","CAR_TYPE","RED_CAR","CLM_FREQ", "URBANICITY", "BLUEBOOK",)

test_kmeans <- test_random_forest %>% mutate_if(is.factor,as.numeric) %>% mutate_if(is.integer,as.numeric)

test_random_forest$CLAIM_FLAG <- factor(test_random_forest$CLAIM_FLAG, levels = c("0", "1"), labels = c("NOacc", "SIacc"))
```

##MODELO NO SUPERVISADO

Con los modelos no supervisados vamos a intentar clasificar por grupos los registros para cuando lleguen nuevos registros poder imputarlos a un grupo de los seleccionados.

Con este metodo podemos ver si en los distintos cluster tenemos distintas probabilidades de siniestro y de esa manera podríamos tener distintas tarifas dependiendo del grupo en el que cayeran los nuevos registros.

###Modelo no supervisado KMEANS


Este modelo esta basado en la minimización de la suma de distancias entre cada objeto y el centroide de su grupo o cluster.

Al ser un modelo de distancias es necesario escalar todas las variables. Para ello utilizamos la sentencia Scale.

Al aplicar esto aparecen ciertos valores sin sentido como edades negativas pero no tiene importancia ya que unicamente vamos a ver distancias.


```{r echo=FALSE}
xiris <- scale(train_kmeans)
```

Primero vamos a buscar el punto optimo de cluster en funcion del minimo error.
 
 Vemos en la figura que la pendiente varía levemente entre diferentes numero de cluster y a partir de 5 no varía sustancialmente por lo que elegiremos 5 como numero de centroides. 
 
```{r echo=FALSE, message=FALSE, warning=FALSE}
# Initialize total within sum of squares error: wss
wss <- 0
wsr <- 0
# For 1 to 15 cluster centers
for (i in 1:10) {
  km.out <- kmeans(xiris, centers = i, nstart = 20)
  # Save total within sum of squares to wss variable
  wss[i] <- km.out$tot.withinss
  wsr[i] <- km.out$betweenss
}

# Plot total within sum of squares vs. number of clusters
plot(1:10, wss, type = "b", 
     xlab = "Número de Clusters", 
     ylab = "Suma de cuadrados DENTRO DE grupos")

plot(1:10, wsr, type = "b", 
     xlab = "Número de Clusters", 
     ylab = "suma Cuadrados ENTRE grupos")

```
Estas caracteristicas de kmeans nos da una idea de la calidad de nuestro modelo. Cuanto menor sea la suma de cuadrados dentro de los grupos y mayor sea entre los grupos mejor será el modelo.

```{r echo=FALSE}
print("Los registros para cada cluster son los siguientes:")
km$size
print("La suma de cuadrados total es")
km$totss
print("La suma de cuadrados entre grupos es")
km$betweenss
print("La suma de cuadrados dentro del grupos es")
km$withinss
print("La suma de cuadrados agrupada de las medidas dentro del grupos es")
km$tot.withinss
print("La Varianza explicada con cinco clusters es")
(km$betweenss/km$totss) * 100
```


Posteriormente al elegir el numero de centroides vamos a ejecutar el modelo y ver las medias de cada variable en cada Cluster y de este modo poder ver si hay diferencias en la siniestralidad (Variable CLAIM FLAG)

```{r echo=FALSE}
set.seed(123)
km <- kmeans(xiris, 5, nstart = 1)
km
aggregate(train_kmeans, by=list(km$cluster), mean)
```

Lo que podemos ver que en los diferentes cluster es que tenemos 3 medias diferenciadas en los 5 cluster de la variable CLAIM_FLAG.

Podriamos decir que tenemos un cluster sin siniestralidad, otros dos con una siniestralidad de un 26% y otros dos con una siniestralidad del 50%.

Si nos fijamos en el numero de registros por cluster un 60% esta en la tarifa del 26% mientras que el otro 40% estaría repartido en 20% buenos y 20% malos conductores.

###Modelo no supervisado HIERARCHICAL CLUSTERING.

```{r echo=FALSE}
clusters <- hclust(dist(train_kmeans))
plot(clusters)
```
Como podemos ver en el dendograma una división apropiada podría ser 6.

```{r echo=FALSE}
clusterCut <- cutree(clusters, 4)
table(clusterCut, train_kmeans$CLAIM_FLAG)
```
 
 Como vemos los clusters creados por el metodo de hierarchical clustering no nos dan una diferenciación clara en base a la siniestralidad de la cartera
 
## MODELO SUPERVISADO

Ahora empezamos con modelos supervisados de clasificación. Estos modelos tienen en cuenta la variable objetivo que en nuestro caso es CLAIM_FLAG.

Vamos a probar el random forest, GLM, KNN, Decision Tree y SVM

###RANDOM FOREST

El modelo random forest nos va a permitir obtener una clasificación de clientes en las clases de tendrá accidente o no tendrá accidente.

Para ello utilizamos la funcion train del paquete caret que nos permite amoldar la formula al modelo y con los distintos parametros además de darnos una pequeña selección de valores de los parametros que no definamos y quedarse con los que mejor accuracy tiene par ala parte de test.

```{r echo=FALSE}
set.seed(342)
modelo_rf <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                   method = "ranger",
                   metric = "Accuracy",
                   num.trees = 500)
modelo_rf

plot(modelo_rf)
```


Como podemos ver en la parte de entrenamiento el algoritmo toma distintos valores para las variables aleatorias elegidas en cada corte (mtry) y para el tipo de modelo utilizado para calcular la pureza de cada nodo.

El valor final elegido es mtry = 17 y metodo de Gini con un accuracy de 76.13% y un capa del 32.21% ambos resultados son los mas altos de las pruebas realizadas.



```{r echo=FALSE}
set.seed(342)
pred_prob_rf <- predict(modelo_rf, newdata = test_random_forest)
matriz_confusion_rf = confusionMatrix(data = pred_prob_rf, reference = test_random_forest$CLAIM_FLAG, positive = "SIacc")
matriz_confusion_rf
kable(matriz_confusion_rf$table)%>%
kable_styling()
```
En la prueba vemos que el accuracy es de 77.54% mejorando el train y el kappa de 35.98%. Como otras variables a tener en cuenta para ver la calidad del modelo esta la sensitivity que mide el acierto de los casos positivos entendido como positivo el identificar los que tienen accidente.Por otro lado la specificity nos dice que porcentage de valores negativos acertamos y este caso acertamos un 90% de los valores negativos.


### GLM

Para el modelo de regresión lineal en el cual no hay que añadir parametros indicamos a la función que el metodo es un GLM con la metrica de decisión el accuracy y que el modelo es de clasificación.

```{r}
set.seed(342)
modelo_logistic <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                         method = "glm",
                         metric = "Accuracy",
                         family = "binomial")
modelo_logistic
```

Para este modelo el accuracy es el 77.09% y el kappa es el 33.7%.

```{r echo=FALSE}
pred_prob_glm <- predict(modelo_logistic, newdata = test_random_forest)
confusionMatrix(data = pred_prob_glm, reference = test_random_forest$CLAIM_FLAG, positive = "SIacc")
confusionMatrix(pred_prob_glm, test_random_forest$CLAIM_FLAG)$overall[1]
confusionMatrix(pred_prob_glm, test_random_forest$CLAIM_FLAG)$overall[2]
```

Si nos fijamos el accuracy sube a 77.4% y el kappa a 34.38%. La sensitivity es de 37.4% con una specificity de 92%.

##DECISION TREE

Los árboles de decisión es un modelo de predicción que partiendo de una base de datos crea diagramas de construcciones lógicas que nos ayudan a resolver problemas (Beltrán, 2015).

En este modelo vamos a dejar que train automaticamente haga la poda y nos de los resultados de varias podas.

```{r echo=FALSE}
set.seed(342)
modelo_C50Tree <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                    #method = "C5.0Tree",
                    method = "rpart",
                    metric = "Accuracy")
                    
modelo_C50Tree

plot(modelo_C50Tree)
```
El accuracy y el kappa para el complexity parameter de un 0.01 es de 74% y de 17% respectivamente.

```{r echo=FALSE}
pred_prob_tree <- predict(modelo_C50Tree, newdata = test_random_forest)
confusionMatrix(data = pred_prob_tree, reference = test_random_forest$CLAIM_FLAG, positive = "SIacc")
```
En este caso vemos que para el test empeora ligeramente pasando a un 73% de accuracy y un 15% de kappa. La sensitivity es de 17% que es realmente baja.


###KNN

k-Nearest Neighbour Classification reconoce patrones en los datos, simplemente midiendo la distancia entre grupos de datos. Se trata de uno de los algoritmos más simples y robustos de aprendizaje automático.

```{r echo=FALSE}
set.seed(342)
modelo_knn <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                    method = "knn",
                    metric = "accuracy",
                    )
modelo_knn

plot(modelo_knn)
```
vemos que el mejor accuracy lo conseguimos con 9 vecinos  con un 68.8% y un kappa de 10%.

```{r echo=FALSE}
pred_prob_knn <- predict(modelo_knn, newdata = test_random_forest)
confusionMatrix(data = pred_prob_knn, reference = test_random_forest$CLAIM_FLAG, positive = "SIacc")
```
Los resultados del acuracy son de un 71%, un kappa de 10% y una sensitivity de 18%. 

```{r echo=FALSE}
knnPredict <- predict(modelo_knn,newdata = test_random_forest , type="prob")
knnROC <- roc(test_random_forest$CLAIM_FLAG,knnPredict[,"NOacc"])
plot(knnROC, type="S", print.thres= 0.5)
knnROC
```
###SVM

El modelo de maquinas de vectores soporte es un modelo que representa a los puntos de muestra en el espacio, separando las clases a 2 espacios lo más amplios posibles mediante un hiperplano de separación definido como el vector entre los 2 puntos, de las 2 clases, más cercanos al que se llama vector soporte. Cuando las nuevas muestras se ponen en correspondencia con dicho modelo, en función de los espacios a los que pertenezcan, pueden ser clasificadas a una o la otra clase.

```{r echo=FALSE}
set.seed(342)
modelo_svmrad <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                   method = "svmRadial",
                   metric = "Accuracy")
modelo_svmrad

plot(modelo_svmrad)
```
Como vemos el mejor accuracy, que asciende a 76.5% lo obtenemos con el cost parameter mas elevado quiere decir que penalizamos más a los datos dentro de los margenes.

```{r echo=FALSE}
pred_prob_svm <- predict(modelo_svmrad, newdata = test_random_forest)
confusionMatrix(data = pred_prob_svm, reference = test_random_forest$CLAIM_FLAG, positive = "SIacc")
```
Finalmente en nuestro set de train el Accuracy sube a 77.4% con un 31% de kappa y un 30.8% de sensitivity.

##COMPARATIVA DE MODELOS

Ahora vamos a comparar los distintos modelos con las 25 resamples que se realizan. Para eso vamos a unir todos los resultados y vamos a comparar por la media de los 25.

```{r echo=FALSE}
modelos <- resamples(list(KNN = modelo_knn, logistic = modelo_logistic,
                arbol = modelo_C50Tree, rf = modelo_rf,
                SVMradial = modelo_svmrad))

metricas_resamples <- modelos$values %>%
                         gather(key = "modelo", value = "valor", -Resample) %>%
                         separate(col = "modelo", into = c("modelo", "metrica"),
                                  sep = "~", remove = TRUE)


#metricas_resamples %>% 
#  group_by(modelo, metrica) %>% 
#  summarise(media = mean(valor)) %>%
#  spread(key = metrica, value = media) %>%
#  arrange(desc(Accuracy))

metricas_resamples %>%
  filter(metrica == "Accuracy") %>%
  group_by(modelo) %>% 
  summarise(media = mean(valor)) %>%
  ggplot(aes(x = reorder(modelo, media), y = media, label = round(media, 2))) +
    geom_segment(aes(x = reorder(modelo, media), y = 0,
                     xend = modelo, yend = media),
                     color = "grey50") +
    geom_point(size = 7, color = "firebrick") +
    geom_text(color = "white", size = 2.5) +
    scale_y_continuous(limits = c(0, 1)) +
    # Accuracy basal
    geom_hline(yintercept = 0.62, linetype = "dashed") +
    annotate(geom = "text", y = 0.6, x = 5.5, label = "Accuracy basal") +
    labs(title = "Validación: Accuracy medio repeated-CV",
         subtitle = "Modelos ordenados por media",
         x = "modelo") +
    coord_flip() +
    theme_bw()
```

Como vemos en el gráfico por media el modelo que mejor accuracy obtiene es el GLM junto con el SVM y seguido por el Random forest a pesar que este ultimo fue el que mejor accuracy nos dio en el modulo de test de las ejecuciones anteriores pero pudo ser por realizar un unico lanzamiento.

##REDUCCION DE LA DIMENSIONALIDAD.



###PCA

Principal Component Analysis (PCA) es un método estadístico que permite simplificar la complejidad de espacios muestrales con muchas dimensiones a la vez que conserva su información.

El primer paso que vamos a dar va a ser generar los componentes principales y ver la desviacion estandar, la proporcion de la varianza y la proporcion acumulativa.

Vemos que con 6 componentes principales explicamos el 50% de la varianza


```{r echo=FALSE}
pca_train <- prcomp(x = train_kmeans, scale = T, center = T)
summary(pca_train)
names(pca_train)
```
```{r echo=FALSE}
pca_train
```
```{r echo=FALSE}
pca_train$center
```

```{r echo=FALSE}
pca_train$scale
```


```{r echo=FALSE}
biplot(pca_train)
```
```{r echo=FALSE}
#Getting proportion of variance for a scree plot
pr.var <- pca_train$sdev^2
pve <- pr.var / sum(pr.var)

# Plot variance explained for each principal component
plot(pve, 
     xlab = "Principal Component",
     ylab = "Proportion of Variance Explained",
     ylim = c(0,0.15), 
     type = "b")

pve
```
Aqui podemos ver que el primer componente principal explica un 13% de la varianza y poco a poco va disminuyendo lo que nos da que pensar que no se va a poder hacer una reducción apropiada de la dimensionalidad.


```{r echo=FALSE}
# Plot cumulative proportion of variance explained
plot(cumsum(pve), xlab = "Principal Component",
     ylab = "Cumulative Proportion of Variance Explained",
     ylim = c(0, 1), type = "b")
cumsum(pve)
```

Tras el analisis de PCA vemos que para que superemos el 80% de explicabilidad necesitamos 13 componentes y para superar el 90% 15.

###TSNE

Otra de las tecnicas de reducción de la dimensionalidad es stochastic neighbor embedding (tSNE) la cual convierte las distancias euclídeas multidimensionales entre pares de observaciones en probabilidades condicionales.

La ventaja con respecto a PCA es que recoge combinaciones no lineales entre las variables originales.

```{r echo=FALSE}
colors = rainbow(length(unique(train$label)))
names(colors) = unique(train$label)

## Executing the algorithm on curated data
tsne <- Rtsne(train_kmeans, dims = 2, perplexity=30, verbose=TRUE, max_iter = 500)
exeTimeTsne<- system.time(Rtsne(train_kmeans, dims = 2, perplexity=30, verbose=TRUE, max_iter = 500))

resultados <- as.data.frame(tsne$Y)
colnames(resultados) <- c("dim_1", "dim_2")
resultados$numero <- as.character(train_kmeans$CLAIM_FLAG)
ggplot(data = resultados, aes(x = dim_1, y = dim_2)) +
  geom_point(aes(color = numero)) + 
  theme_bw()

```
```{r echo=FALSE}
resultados <- as.data.frame(pca_train$x[, 1:2])
resultados$numero <- as.character(train_kmeans$CLAIM_FLAG)
ggplot(data = resultados, aes(x = PC1, y = PC2)) +
  geom_point(aes(color = numero)) + 
  theme_bw()
```
En este escenario, el método tSNE consigue que, al reducir la dimensionalidad, la separación entre observaciones sea sustancialmente mejor que cuando se emplea PCA.

Véase ahora la reducción a un espacio de 3 dimensiones.

```{r echo=FALSE}
library(scatterplot3d)
library(RColorBrewer)
tsne <- Rtsne(X = train_kmeans, is_distance = FALSE, dims = 3, perplexity = 30,
              theta = 0.5, max_iter = 500)

resultados <- as.data.frame(tsne$Y)
colnames(resultados) <- c("dim_1", "dim_2", "dim_3")
resultados$numero <- as.factor(train_kmeans$CLAIM_FLAG)

colores <- brewer.pal(n = 2, name = "Set3")
colores <- colores[as.numeric(resultados$numero)]
scatterplot3d(x = resultados$dim_1,
              y = resultados$dim_2,
              z = resultados$dim_3,
              pch = 20, color = colores, cex.lab = 0.8,
              grid = TRUE, box = FALSE)
legend("bottom", legend = levels(resultados$numero),
      col = colores, pch = 16, 
      inset = -0.23, xpd = TRUE, horiz = TRUE)
```

## HIPERPARAMETROS DE CADA MODELO.

###HIPERPARAMETROS DE GLM

```{r echo=FALSE}
# HIPERPARÁMETROS, NÚMERO DE REPETICIONES Y SEMILLAS PARA CADA REPETICIÓN
#===============================================================================
particiones  <- 10
repeticiones <- 5

# Hiperparámetros
hiperparametros <- data.frame(parameter = "none")

set.seed(123)
seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)
for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(1000, nrow(hiperparametros))
}
seeds[[(particiones * repeticiones) + 1]] <- sample.int(1000, 1)

# DEFINICIÓN DEL ENTRENAMIENTO
#===============================================================================
control_train <- trainControl(method = "repeatedcv", number = particiones,
                              repeats = repeticiones, seeds = seeds,
                              returnResamp = "final", verboseIter = FALSE,
                              allowParallel = TRUE)

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_logistic <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                         method = "glm",
                         tuneGrid = hiperparametros,
                         metric = "Accuracy",
                         trControl = control_train,
                         family = "binomial")
modelo_logistic
```

###HIPERPARAMETROS DE KNN

```{r echo=FALSE}
particiones  <- 10
repeticiones <- 5

# Hiperparámetros
hiperparametros <- data.frame(k = c(1, 2, 5, 10, 15, 20, 30, 50, 100, 200))

set.seed(123)
seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)
for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(1000, nrow(hiperparametros)) 
}
seeds[[(particiones * repeticiones) + 1]] <- sample.int(1000, 1)

# DEFINICIÓN DEL ENTRENAMIENTO
#===============================================================================
control_train <- trainControl(method = "repeatedcv", number = particiones,
                              repeats = repeticiones, seeds = seeds,
                              returnResamp = "final", verboseIter = FALSE,
                              allowParallel = TRUE)

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_knn <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                    method = "knn",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = control_train)
modelo_knn
```


###HIPERPARAMETROS DE DECISION TREE

```{r echo=FALSE}
# HIPERPARÁMETROS, NÚMERO DE REPETICIONES Y SEMILLAS PARA CADA REPETICIÓN
#===============================================================================
particiones  <- 10
repeticiones <- 5

# Hiperparámetros
#hiperparametros <- data.frame(parameter = "none")
hiperparametros <- data.frame(cp = c(0.01, 0.011, 0.012, 0.013, 0.014, 0.015, 0.016, 0.017, 0.018, 0.019))
set.seed(123)
seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)
for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(1000, nrow(hiperparametros))
}
seeds[[(particiones * repeticiones) + 1]] <- sample.int(1000, 1)

# DEFINICIÓN DEL ENTRENAMIENTO
#===============================================================================
control_train <- trainControl(method = "repeatedcv", number = particiones,
                              repeats = repeticiones, seeds = seeds,
                              returnResamp = "final", verboseIter = FALSE,
                              allowParallel = TRUE)

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_C50Tree <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                    method = "rpart",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = control_train)
modelo_C50Tree
```

###HIPERPARAMETROS DE RANDOM FOREST
```{r echo=FALSE}
# HIPERPARÁMETROS, NÚMERO DE REPETICIONES Y SEMILLAS PARA CADA REPETICIÓN
#===============================================================================
particiones  <- 10
repeticiones <- 5

# Hiperparámetros
hiperparametros <- expand.grid(mtry = c(4),
                               min.node.size = c(1, 2, 3, 4, 5, 10, 15, 20, 30),
                               splitrule = "gini")

set.seed(123)
seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)
for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(1000, nrow(hiperparametros))
}
seeds[[(particiones * repeticiones) + 1]] <- sample.int(1000, 1)

# DEFINICIÓN DEL ENTRENAMIENTO
#===============================================================================
control_train <- trainControl(method = "repeatedcv", number = particiones,
                              repeats = repeticiones, seeds = seeds,
                              returnResamp = "final", verboseIter = FALSE,
                              allowParallel = TRUE)

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_rf <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                   method = "ranger",
                   tuneGrid = hiperparametros,
                   metric = "Accuracy",
                   trControl = control_train,
                   # Número de árboles ajustados
                   num.trees = 500)
modelo_rf
```

###HIPERPARAMETROS DE SVM

```{r echo=FALSE}
# HIPERPARÁMETROS, NÚMERO DE REPETICIONES Y SEMILLAS PARA CADA REPETICIÓN
#===============================================================================
particiones  <- 10
repeticiones <- 5


# Hiperparámetros
hiperparametros <- expand.grid(sigma = c(0.001, 0.01, 0.1, 0.5, 1),
                               C = c(1 , 20, 50, 100, 200, 500, 700))
#hiperparametros <- expand.grid(sigma = c(0.001),
#                               C = c(1 , 20))

set.seed(123)
seeds <- vector(mode = "list", length = (particiones * repeticiones) + 1)
for (i in 1:(particiones * repeticiones)) {
  seeds[[i]] <- sample.int(1000, nrow(hiperparametros))
}
seeds[[(particiones * repeticiones) + 1]] <- sample.int(1000, 1)

# DEFINICIÓN DEL ENTRENAMIENTO
#===============================================================================
control_train <- trainControl(method = "repeatedcv", number = particiones,
                              repeats = repeticiones, seeds = seeds,
                              returnResamp = "final", verboseIter = FALSE,
                              allowParallel = TRUE)

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_svmrad <- train(CLAIM_FLAG ~ ., data = train_random_forest,
                   method = "svmRadial",
                   tuneGrid = hiperparametros,
                   metric = "Accuracy",
                   trControl = control_train)
modelo_svmrad
```

###COMPARATIVA DE MODELOS.

Primero vamos a analizar las medias de las valores que nos ha dado nuestro lanzamiento en train para el resultado que ha sido definitivamente el que mas accuracy tenia en cada modelo.

```{r echo=FALSE}
modelos <- list(KNN = modelo_knn, logistic = modelo_logistic,
                arbol = modelo_C50Tree, rf = modelo_rf, SVMRadial = modelo_svmrad)

resultados_resamples <- resamples(modelos)
metricas_resamples <- resultados_resamples$values %>%
                         gather(key = "modelo", value = "valor", -Resample) %>%
                         separate(col = "modelo", into = c("modelo", "metrica"),
                                  sep = "~", remove = TRUE)
metricas_resamples %>% 
  group_by(modelo, metrica) %>% 
  summarise(media = mean(valor)) %>%
  spread(key = metrica, value = media) %>%
  arrange(desc(Accuracy))
```

Como vemos el modelo de Ramdon forest y el logistico están practicamente empatados.

Vamos a verlo de manera gráfica como se distribuyen los valores para cada modelo de las 50 simulaciones realizadas.

```{r echo=FALSE}
metricas_resamples %>% filter(metrica == "Accuracy") %>%
  group_by(modelo) %>% 
  mutate(media = mean(valor)) %>%
  ungroup() %>%
  ggplot(aes(x = reorder(modelo, media), y = valor, color = modelo)) +
    geom_boxplot(alpha = 0.6, outlier.shape = NA) +
    geom_jitter(width = 0.1, alpha = 0.6) +
    scale_y_continuous(limits = c(0, 1)) +
    
    # Accuracy basal
    geom_hline(yintercept = 0.62, linetype = "dashed") +
    annotate(geom = "text", y = 0.6, x = 4.4, label = "Accuracy basal") +
    theme_bw() +
    labs(title = "Validación: Accuracy medio repeated-CV",
         subtitle = "Modelos ordenados por media") +
    coord_flip() +
    theme(legend.position = "none")
```

En principio podemos decir que nos parece con mayor calidad el GLM ya que tiene el diagrama de caja mas estrecho aun teniendo algun outlier.

Para asegurarnos que podriamos diferenciarlos vamos a hacer el test de WILCOXON. Este test es un estadistico que nos ayudará a ver si son significativamente los modelos.


### TEST DE RANGOS DE WILCOXON.

La prueba de los rangos con signo de Wilcoxon es una prueba no paramétrica para comparar el rango medio de dos muestras relacionadas y determinar si existen diferencias entre ellas.


```{r echo=FALSE}
# Comparaciones múltiples con un test suma de rangos de Wilcoxon
# ==============================================================================

metricas_accuracy <- metricas_resamples %>% filter(metrica == "Accuracy")
comparaciones  <- pairwise.wilcox.test(x = metricas_accuracy$valor, 
                                        g = metricas_accuracy$modelo,
                                        paired = TRUE,
                                        p.adjust.method = "holm")

# Se almacenan los p_values en forma de dataframe
comparaciones <- comparaciones$p.value %>%
  as.data.frame() %>%
  rownames_to_column(var = "modeloA") %>%
  gather(key = "modeloB", value = "p_value", -modeloA) %>%
  na.omit() %>%
  arrange(modeloA) 

comparaciones
```

Acorde a las comparaciones por pares, no existen evidencias suficientes para considerar que la capacidad predictiva de los modelos Random Forest, SVM radial y logistica es distinta. 

Por ultimo vamos a 

```{r echo=FALSE}
set.seed(342)

pred_prob_glm_final <- predict(modelo_logistic, newdata = test_random_forest)
pred_prob_svm_final <- predict(modelo_svmrad, newdata = test_random_forest)
pred_prob_rf_final <- predict(modelo_rf, newdata = test_random_forest)
pred_prob_knn_final <- predict(modelo_knn, newdata = test_random_forest)
pred_prob_Tree_final <- predict(modelo_C50Tree, newdata = test_random_forest)

paste("El Accuracy de test del modelo GLM:", round(confusionMatrix(pred_prob_glm_final, test_random_forest$CLAIM_FLAG)$overall[1]*100, 3), "%")
paste("El Accuracy de test del modelo SVM:", round(confusionMatrix(pred_prob_svm_final, test_random_forest$CLAIM_FLAG)$overall[1]*100, 3), "%")
paste("El Accuracy de test del modelo rf:", round(confusionMatrix(pred_prob_rf_final, test_random_forest$CLAIM_FLAG)$overall[1]*100, 3), "%")
paste("El Accuracy de test del modelo knn:", round(confusionMatrix(pred_prob_knn_final, test_random_forest$CLAIM_FLAG)$overall[1]*100, 3), "%")
paste("El Accuracy de test del modelo tree:", round(confusionMatrix(pred_prob_Tree_final, test_random_forest$CLAIM_FLAG)$overall[1]*100, 3), "%")

paste("El Kappa de test del modelo GLM:", round(confusionMatrix(pred_prob_glm_final, test_random_forest$CLAIM_FLAG)$overall[2]*100, 3), "%")
paste("El Kappa de test del modelo SVM:", round(confusionMatrix(pred_prob_svm_final, test_random_forest$CLAIM_FLAG)$overall[2]*100, 3), "%")
paste("El Kappa de test del modelo rf:", round(confusionMatrix(pred_prob_rf_final, test_random_forest$CLAIM_FLAG)$overall[2]*100, 3), "%")
paste("El Kappa de test del modelo knn:", round(confusionMatrix(pred_prob_knn_final, test_random_forest$CLAIM_FLAG)$overall[2]*100, 3), "%")
paste("El Kappa de test del modelo tree:", round(confusionMatrix(pred_prob_Tree_final, test_random_forest$CLAIM_FLAG)$overall[2]*100, 3), "%")

```


###Curva ROC

###ROC modelo Random Forest

```{r echo=FALSE}
predicciones_rf_prob_train <- predict(modelo_randomforest, newdata = train_random_forest)
predicciones_rf_prob_test <- predict(modelo_randomforest, newdata = test_random_forest)

pred1 <- prediction(as.numeric(predicciones_rf_prob_test), as.numeric(test_random_forest$CLAIM_FLAG))

perf1 <- performance(pred1, "tpr", "fpr")

perf2 <- performance(pred1, "auc")

perf2

plot(perf1)

```
###ROC modelo SVM

```{r echo=FALSE}
predicciones_rf_prob_train <- predict(modelo_svmrad_final, newdata = train_random_forest)
predicciones_rf_prob_test <- predict(modelo_svmrad_final, newdata = test_random_forest)

pred1 <- prediction(as.numeric(predicciones_rf_prob_test), as.numeric(test_random_forest$CLAIM_FLAG))

perf1 <- performance(pred1, "tpr", "fpr")

perf2 <- performance(pred1, "auc")

perf2

plot(perf1)

```

###ROC modelo GLM

```{r echo=FALSE}
knnPredict <- predict(modelo_logistic_final,newdata = test_random_forest , type="prob")
knnROC <- roc(test_random_forest$CLAIM_FLAG,knnPredict[,"NOacc"])
plot(knnROC, type="S", print.thres= 0.5)
knnROC
```

###ROC modelo KNN Final

```{r echo=FALSE}
knnPredict <- predict(modelo_knn_final,newdata = test_random_forest , type="prob")
knnROC <- roc(test_random_forest$CLAIM_FLAG,knnPredict[,"NOacc"])
plot(knnROC, type="S", print.thres= 0.5)
knnROC
```

###ROC modelo Decision Tree

```{r echo=FALSE}
knnPredict <- predict(modelo_C50Tree_final,newdata = test_random_forest , type="prob")
knnROC <- roc(test_random_forest$CLAIM_FLAG,knnPredict[,"NOacc"])
plot(knnROC, type="S", print.thres= 0.5)
knnROC
```

###ANOVA

La técnica de análisis de varianza (ANOVA) constituye la herramienta básica para el estudio del efecto de uno o más factores (cada uno con dos o más niveles) sobre la media de una variable continua. Es por lo tanto el test estadístico a emplear cuando se desea comparar las medias de dos o más grupos. Esta técnica puede generalizarse también para estudiar los posibles efectos de los factores sobre la varianza de una variable.

```{r echo=FALSE}
# =============================================================================

# Se crea una semilla para cada partición y cada repetición: el vector debe
# tener B+1 semillas donde B = particiones * repeticiones.
particiones = 10
repeticiones = 5
set.seed(123)
seeds <- sample.int(1000, particiones * repeticiones + 1)

# Control del filtrado
ctrl_filtrado <- sbfControl(functions = rfSBF, method = "repeatedcv",
                            number = particiones, repeats = repeticiones,
                            seeds = seeds, verbose = FALSE, 
                            saveDetails = TRUE, allowParallel = TRUE)
set.seed(234)
rf_sbf <- sbf(CLAIM_FLAG ~ ., data = train_random_forest,
              sbfControl = ctrl_filtrado,
              # argumentos para el modelo de evaluación
              ntree = 500)
```

```{r echo=FALSE}
rf_sbf
```
```{r echo=FALSE}
rf_sbf$optVariables
```


### CONCLUSIONES

Tras la comparativa realizada con los 5 modelos vemos que tenemos una gran rivalidad entre el modelo GLM, el modelo Random forest y el SVM

La metrica de accuracy y de Kappa para los resultados de train y para los de test nos dan levemente mejor para el modelo de GLM con respecto a los otros dos, además en la gráfica de comparativa de modelos podemos ver que la varianza del modelo es levemente mejor en el GLM aunque tras el analisis de rangos de Wilcoxon vemos que estas diferencias entre los modelos no son significativas por lo que asumimos que en estas métricas están igual.

El punto diferenciador es la curva ROC, este indicador se decanta por el modelo GLM ya que en este modelo tiene un valor de 80% mientras que en el modelo de Random forest y SVM tenemos un valor de 65% y 63% por lo que nos decantamos por el modelo GLM para nuestro estudio.

